{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import pyopencl as cl\n",
    "    import pyopencl.array as cl_array\n",
    "    from pyopencl.clrandom import rand as clrand\n",
    "except ImportError:\n",
    "    Warning(\"PyOpenCl not installed\")\n",
    "import os\n",
    "from mako.template import Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AWGN_channel:\n",
    "    \"\"\" Class implements an additive white Gaussian noise channel\n",
    "\n",
    "    The added noise can either be real or complex depending on the arguments of the constructor.\n",
    "    The default value is real.\n",
    "\n",
    "    Attributes:\n",
    "        sigma_n2: a double setting noise variance\n",
    "        complex: a boolean value indicating if noise is complex or not\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma_n2_, complex =False):\n",
    "        \"\"\"Inits the AWGN_channel class\n",
    "        Args:\n",
    "            sigma_n2_: noise variance specified by user\n",
    "            complex: default is false, indicating if noise is complex\n",
    "        \"\"\"\n",
    "        self.sigma_n2 = sigma_n2_\n",
    "        self.complex = complex\n",
    "\n",
    "    def transmission(self, input):\n",
    "        \"\"\"Performs the transmission of an input stream over an AWGN channel\n",
    "        Args:\n",
    "            input: sequence of symbols as numpy array or scalar\n",
    "        Returns:\n",
    "            output: summation of noise and input\n",
    "        \"\"\"\n",
    "        if self.complex:\n",
    "            noise = np.sqrt(self.sigma_n2/2) * np.random.randn(input.shape[0], input.shape[1]) + \\\n",
    "                    1j * np.sqrt(self.sigma_n2/2) * np.random.randn(input.shape[0], input.shape[1])\n",
    "\n",
    "        else:\n",
    "            noise = np.sqrt(self.sigma_n2) * np.random.randn(input.shape[0],input.shape[1])\n",
    "\n",
    "        output = input + noise\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AWGN_Channel_Quantizer:\n",
    "    \"\"\"Implementation of an information optimum quantizer unit assuming BPSK transmission.\n",
    "\n",
    "    The quantizer is generated using the symmetric, sequential information bottleneck algorithm.\n",
    "    This class supports OpenCL for faster quantization and even direct quantization and sample generation on the GPU\n",
    "    (cf. quantize direct).\n",
    "    Although it is theoretical correct to quantize directly, it is preferable to create a more realistic\n",
    "    communication chain including an encoder and modulator in your system instead of using this direct quantization approach.\n",
    "\n",
    "    Attributes:\n",
    "        sigma_n2: noise variance corresponding to the desired design-Eb/N0 of the decoder\n",
    "        AD_max_abs: limits of the quantizer\n",
    "        cardinality_Y: number of steps used for the fine quantization of the input distribution of the quantizer\n",
    "        cardinality_T: cardinality of the compression variable representing the quantizer output\n",
    "\n",
    "        limits: borders of the quantizer regions\n",
    "        y_vec: fine quantization of the input domain\n",
    "        delta: spacing between two values in the quantized input domain (cf. y_vec)\n",
    "\n",
    "        x_vec: position of the means of the involved Gaussians\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma_n2_, AD_max_abs_, cardinality_T_, cardinality_Y_, dont_calc = False):\n",
    "        \"\"\"Inits the quantizer class.\"\"\"\n",
    "        self.nror = 5\n",
    "        self.limits = np.zeros(cardinality_T_)\n",
    "\n",
    "        self.sigma_n2 = sigma_n2_\n",
    "        self.cardinality_T = cardinality_T_\n",
    "        self.cardinality_Y = cardinality_Y_\n",
    "        self.AD_max_abs = AD_max_abs_\n",
    "\n",
    "        self.y_vec = np.linspace(-self.AD_max_abs, +self.AD_max_abs, self.cardinality_Y)\n",
    "        self.x_vec = np.array([-1, 1])\n",
    "        self.delta = self.y_vec[1] - self.y_vec[0]\n",
    "        if not dont_calc:\n",
    "            self.calc_quanti()\n",
    "\n",
    "    def calc_quanti(self):\n",
    "        \"\"\"Determines the information optimum quantizer for the given input distribution\"\"\"\n",
    "\n",
    "        # calculate p_xy based on sigma_n2 and AD_max_abs;\n",
    "        # init as normal with mean + 1\n",
    "        p_y_given_x_equals_zero = norm.pdf(self.y_vec, loc=1, scale=np.sqrt(self.sigma_n2)) * self.delta\n",
    "\n",
    "        # truncate t account for distortion introduced by the quantizer limits then\n",
    "        p_y_given_x_equals_zero[-1] += self.gaussian_over_prob(self.AD_max_abs, 1)\n",
    "        p_y_given_x_equals_zero[0] += self.gaussian_under_prob(-self.AD_max_abs, 1)\n",
    "\n",
    "        # flip distribution, which realizes mean -1 or a transmitted bit = 1\n",
    "        p_y_given_x_equals_one = p_y_given_x_equals_zero[::-1]\n",
    "\n",
    "        self.p_xy = 0.5 * np.hstack((p_y_given_x_equals_zero[:,np.newaxis], p_y_given_x_equals_one[:,np.newaxis]))\n",
    "\n",
    "        self.p_xy = self.p_xy / self.p_xy.sum() #normalize for munerical stability\n",
    "\n",
    "        # run the symmetric sequential Information Bottleneck algorithm\n",
    "        IB_class = symmetric_sIB(self.p_xy, self.cardinality_T, self.nror)\n",
    "        IB_class.run_IB_algo()\n",
    "\n",
    "        # store the results\n",
    "        [self.p_t_given_y, self.p_x_given_t, self.p_t] = IB_class.get_results()\n",
    "\n",
    "        # calculate\n",
    "        # p(t | X = 0)=p(X=0 | t)\n",
    "        # p(t) / p(X=0)\n",
    "        self.p_x_given_t = self.p_x_given_t / self.p_x_given_t.sum(1)[:,np.newaxis]\n",
    "        self.p_x_and_t = self.p_x_given_t * self.p_t[:,np.newaxis]\n",
    "        p_t_given_x_equals_zero = self.p_x_and_t[:, 0] / 0.5\n",
    "\n",
    "        self.cdf_t_given_x_equals_zero = np.append([0], np.cumsum(p_t_given_x_equals_zero))\n",
    "\n",
    "        self.output_LLRs = np.log(self.p_x_and_t[:, 0] / self.p_x_and_t[:, 1])\n",
    "        self.calc_limits()\n",
    "\n",
    "    @classmethod\n",
    "    def from_generated(cls, cdf_t_given_x_equals_zero_):\n",
    "        cdf_t_given_x_equals_zero = cdf_t_given_x_equals_zero_\n",
    "        return cls(cdf_t_given_x_equals_zero,)\n",
    "\n",
    "    def gaussian_over_prob(self, x, mu):\n",
    "        \"\"\"Compensates the ignored probability mass caused by fixing the region to +- AD_abs_max.\"\"\"\n",
    "\n",
    "        prob = norm.sf((x-mu+self.delta/2)/np.sqrt(self.sigma_n2))\n",
    "        return prob\n",
    "\n",
    "    def gaussian_under_prob(self, x, mu):\n",
    "        \"\"\"Compensates the ignored probability mass caused by fixing the region to +- AD_abs_max.\"\"\"\n",
    "\n",
    "        prob = 1-self.gaussian_over_prob(x-self.delta,mu)\n",
    "        return prob\n",
    "\n",
    "    def calc_limits(self):\n",
    "        \"\"\"Calculates the limits of the quantizer borders\"\"\"\n",
    "\n",
    "        for i in range(self.cardinality_T):\n",
    "            cur_vec = (self.p_t_given_y[:, i] == 1).nonzero()\n",
    "            self.limits[i] = self.y_vec[cur_vec[0].min()]\n",
    "\n",
    "        self.limits[int(self.cardinality_T/2)] = 0\n",
    "        #self.limits[-1]=self.AD_max_abs\n",
    "\n",
    "    def quantize_direct(self, input_bits):\n",
    "        \"\"\"Direct quantization without the need of a channel in between since the inversion method is used.\n",
    "        The clusters are directly sampled.\n",
    "        \"\"\"\n",
    "        # create uniform samples\n",
    "        rand_u = np.random.rand(input_bits.shape[0],input_bits.shape[1])\n",
    "\n",
    "        # create samples ~ p(t | X = 0) using inversion method\n",
    "        if input_bits.shape[1] > 1:\n",
    "            output_integers = ((np.repeat(rand_u[:,:,np.newaxis], self.cardinality_T+1, axis=2)-self.cdf_t_given_x_equals_zero) > 0).sum(2)-1\n",
    "            output_integers[input_bits.astype(bool)] = self.cardinality_T - 1 - output_integers[input_bits.astype(bool)]\n",
    "        else:\n",
    "            output_integers = ((rand_u - self.cdf_t_given_x_equals_zero) > 0).sum(1) - 1\n",
    "            # \"mirror\" a sample, when the input bit is 1, otherwise do nothing.\n",
    "            output_integers[input_bits.astype(bool)[:, 0]] = self.cardinality_T - 1 - output_integers[\n",
    "            input_bits.astype(bool)[:, 0]]\n",
    "\n",
    "        return output_integers\n",
    "\n",
    "    def quantize_on_host(self,x):\n",
    "        \"\"\"Quantizes the received samples on the local machine\"\"\"\n",
    "        if x.shape[1] > 1:\n",
    "            cluster = ((np.repeat(x[:,:,np.newaxis], self.cardinality_T, axis=2)-self.limits) > 0).sum(2)-1\n",
    "            cluster[cluster == -1] = 0\n",
    "        else:\n",
    "            cluster = np.sum((x - self.limits) > 0, 1) -1\n",
    "            cluster[cluster==-1] = 0\n",
    "\n",
    "        return cluster\n",
    "\n",
    "    def init_OpenCL_quanti(self, N_var,msg_at_time,return_buffer_only=False):\n",
    "        \"\"\"Inits the OpenCL context and transfers all static data to the device\"\"\"\n",
    "\n",
    "        self.context = cl.create_some_context()\n",
    "\n",
    "        print(self.context.get_info(cl.context_info.DEVICES))\n",
    "        path = os.path.split(os.path.abspath(__file__))\n",
    "        kernelsource = open(os.path.join(path[0], 'kernels_quanti_template.cl')).read()\n",
    "\n",
    "        tpl = Template(kernelsource)\n",
    "        rendered_tp = tpl.render(Nvar=N_var)\n",
    "\n",
    "        self.program = cl.Program(self.context, str(rendered_tp)).build()\n",
    "\n",
    "        self.return_buffer_only = return_buffer_only\n",
    "\n",
    "        # Set up OpenCL\n",
    "        self.queue = cl.CommandQueue(self.context)\n",
    "        self.quantize = self.program.quantize\n",
    "        self.quantize.set_scalar_arg_dtypes([np.int32, None, None, None])\n",
    "        self.quantize_LLR = self.program.quantize_LLR\n",
    "        self.quantize_LLR.set_scalar_arg_dtypes([np.int32, None, None, None,None])\n",
    "        self.limit_buff = cl_array.to_device(self.queue, self.cdf_t_given_x_equals_zero.astype(np.float64))\n",
    "        self.cluster_buff = cl_array.empty(self.queue, (N_var, msg_at_time), dtype=np.int32)\n",
    "        self.LLR_buff = cl_array.empty(self.queue, (N_var, msg_at_time), dtype=np.float64)\n",
    "        self.LLR_values_buff = cl_array.to_device(self.queue, self.output_LLRs.astype(np.float64))\n",
    "\n",
    "    def quantize_OpenCL(self, x):\n",
    "        \"\"\"Quantizes the received distorted samples on the graphic card\"\"\"\n",
    "\n",
    "        # Create OpenCL buffers\n",
    "\n",
    "        x_buff = cl_array.to_device(self.queue,x.astype(np.float64) )\n",
    "        limit_buff = cl_array.to_device(self.queue, self.limits.astype(np.float64))\n",
    "        cluster_buff = cl_array.empty_like(x_buff.astype(np.int32))\n",
    "\n",
    "        self.quantize(self.queue, x.shape, None, self.cardinality_T, x_buff.data, limit_buff.data, cluster_buff.data)\n",
    "        self.queue.finish()\n",
    "\n",
    "        if self.return_buffer_only:\n",
    "            return cluster_buff\n",
    "        else:\n",
    "            clusters = cluster_buff.get()\n",
    "            return clusters\n",
    "\n",
    "    def quantize_direct_OpenCL(self,N_var,msg_at_time):\n",
    "        \"\"\"Direct quantization without the need of a channel in between since the inversion method is used.\n",
    "        The clusters are directly sampled. In this scenario the all-zeros codeword is considered such that no data\n",
    "        needs to be transferred to the graphic card.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        #rand_u_buff = clrand(self.queue, (N_var,msg_at_time), dtype=np.float64, a=0, b=1)\n",
    "\n",
    "        rand_u = np.random.rand(N_var,msg_at_time)\n",
    "\n",
    "        # Create OpenCL buffers\n",
    "\n",
    "        rand_u_buff = cl_array.to_device(self.queue,rand_u.astype(np.float64) )\n",
    "\n",
    "\n",
    "\n",
    "        self.quantize(self.queue, (N_var,msg_at_time), None, self.cardinality_T+1, rand_u_buff.data,\n",
    "                      self.limit_buff.data, self.cluster_buff.data)\n",
    "\n",
    "\n",
    "        self.queue.finish()\n",
    "\n",
    "        if self.return_buffer_only:\n",
    "            return self.cluster_buff\n",
    "        else:\n",
    "            clusters = self.cluster_buff.get()\n",
    "            return clusters\n",
    "\n",
    "    def quantize_direct_OpenCL_LLR(self,N_var,msg_at_time):\n",
    "        \"\"\" Returns the LLRs of the sampled cluster indices. These indices correspond to the quantized outputs which\n",
    "        are found directly on the graphic card using the inversion method. \"\"\"\n",
    "\n",
    "        rand_u = np.random.rand(N_var,msg_at_time)\n",
    "\n",
    "        # Create OpenCL buffers\n",
    "        rand_u_buff = cl_array.to_device(self.queue,rand_u.astype(np.float64) )\n",
    "\n",
    "        self.quantize_LLR(self.queue, (N_var,msg_at_time), None, self.cardinality_T+1, rand_u_buff.data,\n",
    "                      self.limit_buff.data, self.LLR_values_buff.data, self.LLR_buff.data)\n",
    "\n",
    "        self.queue.finish()\n",
    "\n",
    "        if self.return_buffer_only:\n",
    "            return self.LLR_buff\n",
    "        else:\n",
    "            LLRs = self.LLR_buff.get()\n",
    "            return LLRs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LDPC_BPSK_Transmitter:\n",
    "\n",
    "    def __init__(self, filename_H_,  msg_at_time=1):\n",
    "        self.filename_H = filename_H_\n",
    "        self.H_sparse = self.load_check_mat(self.filename_H)\n",
    "\n",
    "        self.encoder = LDPCEncoder(self.filename_H)\n",
    "\n",
    "        # analyze the H matrix and set all decoder variables\n",
    "        self.set_code_parameters()\n",
    "\n",
    "        self.data_len = (self.R_c * self.codeword_len).astype(int)\n",
    "\n",
    "        self.last_transmitted_bits = []\n",
    "        self.msg_at_time = msg_at_time\n",
    "\n",
    "    def set_code_parameters(self):\n",
    "        self.degree_checknode_nr = ((self.H_sparse).sum(1)).astype(np.int).A[:, 0]  # which check node has which degree?\n",
    "        self.degree_varnode_nr = ((self.H_sparse).sum(0)).astype(np.int).A[0,\n",
    "                                 :]  # which variable node has which degree?\n",
    "\n",
    "        self.N_v = self.H_sparse.shape[1]  # How many variable nodes are present?\n",
    "        self.N_c = self.H_sparse.shape[0]  # How many checknodes are present?\n",
    "\n",
    "        self.d_c_max = self.degree_checknode_nr.max()\n",
    "        self.d_v_max = self.degree_varnode_nr.max()\n",
    "\n",
    "        self.codeword_len = self.H_sparse.shape[1]\n",
    "        row_sum = self.H_sparse.sum(0).A[0, :]\n",
    "        col_sum = self.H_sparse.sum(1).A[:, 0]\n",
    "        d_v_dist_val = np.unique(row_sum)\n",
    "        d_v_dist = np.zeros(int(d_v_dist_val.max()))\n",
    "\n",
    "        for d_v in np.sort(d_v_dist_val).astype(np.int):\n",
    "            d_v_dist[d_v - 1] = (row_sum == d_v).sum()\n",
    "        d_v_dist = d_v_dist / d_v_dist.sum()\n",
    "\n",
    "        d_c_dist_val = np.unique(col_sum)\n",
    "        d_c_dist = np.zeros(int(d_c_dist_val.max()))\n",
    "\n",
    "        for d_c in np.sort(d_c_dist_val).astype(np.int):\n",
    "            d_c_dist[d_c - 1] = (col_sum == d_c).sum()\n",
    "\n",
    "        d_c_dist = d_c_dist / d_c_dist.sum()\n",
    "        nom = np.dot(d_v_dist, np.arange(d_v_dist_val.max()) + 1)\n",
    "        den = np.dot(d_c_dist, np.arange(d_c_dist_val.max()) + 1)\n",
    "\n",
    "        self.R_c = 1 - nom / den\n",
    "\n",
    "    def alistToNumpy(self, lines):\n",
    "        \"\"\"Converts a parity-check matrix in AList format to a 0/1 numpy array. The argument is a\n",
    "       list-of-lists corresponding to the lines of the AList format, already parsed to integers\n",
    "        if read from a text file.\n",
    "        The AList format is introduced on http://www.inference.phy.cam.ac.uk/mackay/codes/alist.html.\n",
    "        This method supports a \"reduced\" AList format where lines 3 and 4 (containing column and row\n",
    "        weights, respectively) and the row-based information (last part of the Alist file) are omitted.\n",
    "        Example:\n",
    "             >>> alistToNumpy([[3,2], [2, 2], [1,1,2], [2,2], [1], [2], [1,2], [1,2,3,4]])\n",
    "            array([[1, 0, 1],\n",
    "                  [0, 1, 1]])\n",
    "        \"\"\"\n",
    "\n",
    "        nCols, nRows = lines[0]\n",
    "        if len(lines[2]) == nCols and len(lines[3]) == nRows:\n",
    "            startIndex = 4\n",
    "        else:\n",
    "            startIndex = 2\n",
    "        matrix = np.zeros((nRows, nCols), dtype=np.int)\n",
    "        for col, nonzeros in enumerate(lines[startIndex:startIndex + nCols]):\n",
    "            for rowIndex in nonzeros:\n",
    "                if rowIndex != 0:\n",
    "                    matrix[rowIndex - 1, col] = 1\n",
    "\n",
    "        return matrix\n",
    "\n",
    "    def load_sparse_csr(self, filename):\n",
    "        loader = np.load(filename)\n",
    "        return sci.sparse.csr_matrix((loader['data'], loader['indices'], loader['indptr']),\n",
    "                              shape=loader['shape'])\n",
    "\n",
    "    def load_check_mat(self, filename):\n",
    "        if filename.endswith('.npy') or filename.endswith('.npz'):\n",
    "            if filename.endswith('.npy'):\n",
    "                H = np.load(filename)\n",
    "                H_sparse = sci.sparse.csr_matrix(H)\n",
    "            else:\n",
    "                H_sparse = self.load_sparse_csr(filename)\n",
    "        else:\n",
    "            arrays = [np.array(list(map(int, line.split()))) for line in open(filename)]\n",
    "            H = self.alistToNumpy(arrays)\n",
    "            H_sparse = sci.sparse.csr_matrix(H)\n",
    "        return H_sparse\n",
    "\n",
    "    def transmit(self):\n",
    "\n",
    "        uncoded_msgs = np.random.randint(0,2, (self.data_len, self.msg_at_time))\n",
    "\n",
    "        #uncoded_msgs = np.zeros( (self.data_len, self.msg_at_time) )\n",
    "        encoded_msgs = np.zeros((self.codeword_len, self.msg_at_time))\n",
    "\n",
    "\n",
    "        for i in range(self.msg_at_time):\n",
    "\n",
    "            encoded_msgs[:, i]=self.encoder.encode_c(uncoded_msgs[:, i])\n",
    "\n",
    "        self.last_transmitted_bits = uncoded_msgs\n",
    "\n",
    "        data = self.BPSK_mapping(encoded_msgs)\n",
    "\n",
    "        return data\n",
    "\n",
    "    def BPSK_mapping(self, X):\n",
    "\n",
    "        data = np.ones((self.codeword_len, self.msg_at_time))\n",
    "        data[X == 1] = -1\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AWGN_Discrete_Density_Evolution_class:\n",
    "    \"\"\" Generates a discrete LDPC decoder for a AWGN channel and a regular LDPC code for a certain design-Eb/N0.\n",
    "\n",
    "    The assumed modulation is BPSK which is considered in the quantizer design.\n",
    "    Attributes:\n",
    "        sigma_n2: noise variance corresponding to the desired design-Eb/N0 of the decoder\n",
    "        AD_max_abs: limits of the quantizer\n",
    "        cardinality_Y_channel: number of steps used for the fine quantization of the input distribution of the quantizer\n",
    "        cardinality_T_channel: cardinality of the compression variable representing the quantizer output\n",
    "\n",
    "        cardinality_T_decoder_ops: cardinality of the compression variables inside the decoder\n",
    "\n",
    "        d_c: check node degree\n",
    "        d_v: variable node degree\n",
    "\n",
    "        imax: maximum number of iterations\n",
    "        nror: number of runs of the Information Bottleneck algorithm\n",
    "\n",
    "        Trellis_checknodevector_a:  vectorized version of the trellis which holds the resulting outputs for a certain\n",
    "                                    input and iteration at a check node\n",
    "        Trellis_varnodevector_a:  vectorized version of the trellis which holds the resulting outputs for a certain\n",
    "                                    input and iteration at a variable node\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma_n2_, AD_max_abs_,cardinality_Y_channel_, cardinality_T_channel_,\n",
    "                 cardinality_T_decoder_ops_,d_v_, d_c_, i_max_, nror_):\n",
    "        \"\"\"Inits the AWGN_Discrete_Density_Evolution_class with the following arguments\n",
    "\n",
    "        Args:\n",
    "            sigma_n2_: noise variance corresponding to the desired design-Eb/N0 of the decoder\n",
    "            AD_max_abs_: limits of the quantizer\n",
    "            cardinality_Y_channel_: number of steps used for the fine quantization of the input distribution of the quantizer\n",
    "            cardinality_T_channel_: cardinality of the compression variable representing the quantizer output\n",
    "\n",
    "            cardinality_T_decoder_ops_: cardinality of the compression variables inside the decoder\n",
    "\n",
    "            d_c_: check node degree\n",
    "            d_v_: variable node degree\n",
    "\n",
    "            i_max_: maximum number of iterations\n",
    "            nror_: number of runs of the Information Bottleneck algorithm\n",
    "        \"\"\"\n",
    "        # copy input arguments to class attributes\n",
    "        self.sigma_n2 = sigma_n2_\n",
    "        self.AD_max_abs = AD_max_abs_\n",
    "\n",
    "        self.cardinality_Y_channel = cardinality_Y_channel_\n",
    "        self.cardinality_T_channel = cardinality_T_channel_\n",
    "        self.cardinality_T_decoder_ops = cardinality_T_decoder_ops_\n",
    "\n",
    "        self.d_v = d_v_\n",
    "        self.d_c = d_c_\n",
    "\n",
    "        R_c = 1 - self.d_v / self.d_c\n",
    "        if R_c > 0:\n",
    "            self.EbN0 = -10 * np.log10(self.sigma_n2 * 2 * R_c)\n",
    "\n",
    "        self.imax = i_max_\n",
    "        self.nror = nror_\n",
    "\n",
    "        self.build_quantizer()\n",
    "\n",
    "\n",
    "        self.Trellis_checknodevector_a = 0\n",
    "        self.Trellis_varnodevector_a = 0\n",
    "\n",
    "    def set_code_parameters(self):\n",
    "        \"\"\"Analysis of the given parity check matrix.\n",
    "        Determines node-degree distribution, edge-degree distribution and code rate\n",
    "        \"\"\"\n",
    "        self.degree_checknode_nr = ((self.H_sparse).sum(1)).astype(np.int).A[:, 0]  # which check node has which degree?\n",
    "        self.degree_varnode_nr = ((self.H_sparse).sum(0)).astype(np.int).A[0,\n",
    "                                 :]  # which variable node has which degree?\n",
    "\n",
    "        self.N_v = self.H_sparse.shape[1]  # How many variable nodes are present?\n",
    "        self.N_c = self.H_sparse.shape[0]  # How many checknodes are present?\n",
    "\n",
    "        self.d_c_max = self.degree_checknode_nr.max()\n",
    "        self.d_v_max = self.degree_varnode_nr.max()\n",
    "\n",
    "        self.codeword_len = self.H_sparse.shape[1]\n",
    "        row_sum = self.H_sparse.sum(0).A[0, :]\n",
    "        col_sum = self.H_sparse.sum(1).A[:, 0]\n",
    "        d_v_dist_val = np.unique(row_sum)\n",
    "        d_v_dist = np.zeros(int(d_v_dist_val.max()))\n",
    "\n",
    "        for d_v in np.sort(d_v_dist_val).astype(np.int):\n",
    "            d_v_dist[d_v - 1] = (row_sum == d_v).sum()\n",
    "\n",
    "        d_v_dist = d_v_dist / d_v_dist.sum()\n",
    "\n",
    "        d_c_dist_val = np.unique(col_sum)\n",
    "        d_c_dist = np.zeros(int(d_c_dist_val.max()))\n",
    "\n",
    "        for d_c in np.sort(d_c_dist_val).astype(np.int):\n",
    "            d_c_dist[d_c - 1] = (col_sum == d_c).sum()\n",
    "\n",
    "        d_c_dist = d_c_dist / d_c_dist.sum()\n",
    "\n",
    "        nom = np.dot(d_v_dist, np.arange(d_v_dist_val.max()) + 1)\n",
    "        den = np.dot(d_c_dist, np.arange(d_c_dist_val.max()) + 1)\n",
    "\n",
    "        self.lambda_vec = convert_node_to_edge_degree(d_v_dist)\n",
    "        self.rho_vec = convert_node_to_edge_degree(d_c_dist)\n",
    "\n",
    "        self.R_c = 1 - nom / den\n",
    "\n",
    "    def alistToNumpy(self, lines):\n",
    "        \"\"\"Converts a parity-check matrix in AList format to a 0/1 numpy array. The argument is a\n",
    "        list-of-lists corresponding to the lines of the AList format, already parsed to integers\n",
    "        if read from a text file.\n",
    "        The AList format is introduced on http://www.inference.phy.cam.ac.uk/mackay/codes/alist.html.\n",
    "        This method supports a \"reduced\" AList format where lines 3 and 4 (containing column and row\n",
    "        weights, respectively) and the row-based information (last part of the Alist file) are omitted.\n",
    "        Example:\n",
    "             >>> alistToNumpy([[3,2], [2, 2], [1,1,2], [2,2], [1], [2], [1,2], [1,2,3,4]])\n",
    "            array([[1, 0, 1],\n",
    "                  [0, 1, 1]])\n",
    "        \"\"\"\n",
    "\n",
    "        nCols, nRows = lines[0]\n",
    "        if len(lines[2]) == nCols and len(lines[3]) == nRows:\n",
    "            startIndex = 4\n",
    "        else:\n",
    "            startIndex = 2\n",
    "        matrix = np.zeros((nRows, nCols), dtype=np.int)\n",
    "        for col, nonzeros in enumerate(lines[startIndex:startIndex + nCols]):\n",
    "            for rowIndex in nonzeros:\n",
    "                if rowIndex != 0:\n",
    "                    matrix[rowIndex - 1, col] = 1\n",
    "\n",
    "        return matrix\n",
    "\n",
    "    def load_sparse_csr(self, filename):\n",
    "        \"\"\"Performs loading of a sparse parity check matrix which is stored in a *.npy file.\"\"\"\n",
    "        loader = np.load(filename)\n",
    "        return sci.sparse.csr_matrix((loader['data'], loader['indices'], loader['indptr']),\n",
    "                                     shape=loader['shape'])\n",
    "\n",
    "    def load_check_mat(self, filename):\n",
    "        \"\"\"Performs loading of a predefined parity check matrix.\"\"\"\n",
    "        if filename.endswith('.npy') or filename.endswith('.npz'):\n",
    "            if filename.endswith('.npy'):\n",
    "                H = np.load(filename)\n",
    "                H_sparse = sci.sparse.csr_matrix(H)\n",
    "            else:\n",
    "                H_sparse = self.load_sparse_csr(filename)\n",
    "        else:\n",
    "            arrays = [np.array(list(map(int, line.split()))) for line in open(filename)]\n",
    "            H = self.alistToNumpy(arrays)\n",
    "            H_sparse = sci.sparse.csr_matrix(H)\n",
    "        return H_sparse\n",
    "\n",
    "    def build_quantizer(self):\n",
    "        \"\"\"Generates instance of a quantizer for BPSK and an AWGN channel for the given characteristics.\"\"\"\n",
    "        quanti = AWGN_Channel_Quantizer_BPSK(self.sigma_n2,self.AD_max_abs,self.cardinality_T_channel,self.cardinality_Y_channel)\n",
    "        self.p_x_and_t_input = quanti.p_x_and_t\n",
    "\n",
    "    def run_discrete_density_evolution(self):\n",
    "        \"\"\"Performs the discrete density evolution using the input distributions obtained from the quantizer.\n",
    "        The resulting trellis diagram is stored in a vector that can be used for the real decoder later.\n",
    "        \"\"\"\n",
    "        DDE_inst = discrete_DE(self.p_x_and_t_input, self.cardinality_T_decoder_ops,\n",
    "                               self.d_v, self.d_c, self.imax, self.nror)\n",
    "\n",
    "        DDE_inst.run_discrete_Density_Evolution()\n",
    "\n",
    "        self.Trellis_checknodevector_a = DDE_inst.Trellis_checknodevector_a\n",
    "        self.Trellis_varnodevector_a = DDE_inst.Trellis_varnodevector_a\n",
    "\n",
    "        self.DDE_inst_data = DDE_inst.__dict__\n",
    "\n",
    "    def save_config(self,text=''):\n",
    "        \"\"\"Saves the instance.\"\"\"\n",
    "        #timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "        timestr =''\n",
    "\n",
    "        output = open('decoder_config_EbN0_gen_' + str(self.EbN0) + '_' + str(\n",
    "            self.cardinality_T_decoder_ops) + timestr + text + '.pkl', 'wb')\n",
    "\n",
    "        # Pickle dictionary using protocol -1.\n",
    "        pickle.dump(self.__dict__, output, protocol=-1)\n",
    "\n",
    "class AWGN_Discrete_Density_Evolution_class_irregular(AWGN_Discrete_Density_Evolution_class):\n",
    "    \"\"\"Inherited from base class AWGN_Discrete_Density_Evolution_class.\n",
    "\n",
    "    Generalization for irregular codes. Thus a new discrete density evolution schemes is used.\n",
    "\n",
    "    Attributes:\n",
    "        filename_H: filename of the parity check matrix of the considered code\n",
    "        H_sparse: corresponding parity check matrix for the considered code\n",
    "\n",
    "        matching_vector_varnode: holds the deterministic mapping found when performing message alginment for a\n",
    "                                 variable noce\n",
    "        matching_vector_checknode: holds the deterministic mapping found when performing message alginment for a\n",
    "                                   check node\n",
    "\n",
    "        match: boolean indicating if alignment should be used or not\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma_n2_, AD_max_abs_,cardinality_Y_channel_, cardinality_T_channel_,\n",
    "                 cardinality_T_decoder_ops_,filename_H_, i_max_, nror_,match=True):\n",
    "        \"\"\"Inits AWGN_Discrete_Density_Evolution_class_irregular class.\n",
    "\n",
    "        Args:\n",
    "            filename_H_: filename of parity check matrix\n",
    "            match: boolean indicating if alignment should be used or not\n",
    "        \"\"\"\n",
    "        self.filename_H = filename_H_\n",
    "        self.H_sparse = self.load_check_mat(self.filename_H)\n",
    "        self.set_code_parameters()\n",
    "        AWGN_Discrete_Density_Evolution_class.__init__(self, sigma_n2_,\n",
    "                                                       AD_max_abs_, cardinality_Y_channel_, cardinality_T_channel_,\n",
    "                                                       cardinality_T_decoder_ops_, self.d_v_max, self.d_c_max ,\n",
    "                                                       i_max_, nror_)\n",
    "\n",
    "        self.EbN0 = -10 * np.log10(self.sigma_n2 * 2 * self.R_c)\n",
    "        self.match = match\n",
    "\n",
    "    def run_discrete_density_evolution(self):\n",
    "        \"\"\"Runs discrete density evolution for irregular codes\n",
    "\n",
    "        Returns also two matching vectors describing the deterministic transformation obtained by message alingment\n",
    "        \"\"\"\n",
    "        DDE_inst = discrete_DE_irregular(self.p_x_and_t_input, self.cardinality_T_decoder_ops,\n",
    "                               self.lambda_vec, self.rho_vec, self.imax, self.nror, match=self.match)\n",
    "\n",
    "        DDE_inst.run_discrete_Density_Evolution()\n",
    "\n",
    "        self.Trellis_checknodevector_a = DDE_inst.Trellis_checknodevector_a\n",
    "        self.Trellis_varnodevector_a = DDE_inst.Trellis_varnodevector_a\n",
    "        self.matching_vector_checknode = DDE_inst.matching_vector_checknode\n",
    "        self.matching_vector_varnode = DDE_inst.matching_vector_varnode\n",
    "\n",
    "\n",
    "        self.DDE_inst_data = DDE_inst.__dict__\n",
    "\n",
    "class AWGN_Discrete_Density_Evolution_class_irregular_QAM(AWGN_Discrete_Density_Evolution_class_irregular):\n",
    "    \"\"\"Inherited from base class AWGN_Discrete_Density_Evolution_class_irregular.\n",
    "\n",
    "    Adapted version for an irregular LDPC code, an AWGN channel and QAM modulation.\n",
    "    Thus, the quantizer is replaced.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sigma_n2_,\n",
    "                 AD_max_abs_,\n",
    "                 cardinality_Y_channel_,\n",
    "                 cardinality_T_channel_,\n",
    "                 cardinality_T_decoder_ops_,\n",
    "                 filename_H_,\n",
    "                 encoding_table,\n",
    "                 sqrt_M,\n",
    "                 i_max_,\n",
    "                 nror_,\n",
    "                 match=True):\n",
    "        \"\"\"Inits AWGN_Discrete_Density_Evolution_class_irregular_QAM class\"\"\"\n",
    "\n",
    "        self.encoding_table = encoding_table\n",
    "        self.sqrt_M = sqrt_M\n",
    "        self.num_bits = int(np.log2(sqrt_M) * 2)\n",
    "\n",
    "        AWGN_Discrete_Density_Evolution_class_irregular.__init__(self,sigma_n2_,\n",
    "                                                                 AD_max_abs_,\n",
    "                                                                 cardinality_Y_channel_,\n",
    "                                                                 cardinality_T_channel_,\n",
    "                                                                 cardinality_T_decoder_ops_,\n",
    "                                                                 filename_H_,\n",
    "                                                                 i_max_,\n",
    "                                                                 nror_,\n",
    "                                                                 match)\n",
    "\n",
    "\n",
    "\n",
    "        self.EbN0 = -10 * np.log10(self.sigma_n2 * self.R_c * self.num_bits)\n",
    "\n",
    "    def build_quantizer(self):\n",
    "        \"\"\"Generates a quantizer of the AWGN channel output where the used modulation scheme is QAM.\"\"\"\n",
    "\n",
    "        quanti = AWGN_Channel_Quantizer_QAM(self.sigma_n2,\n",
    "                                                 self.AD_max_abs,\n",
    "                                                 self.cardinality_T_channel,\n",
    "                                                 self.cardinality_Y_channel,\n",
    "                                                 self.encoding_table,\n",
    "                                                 sqrt_M=self.sqrt_M )\n",
    "        self.p_x_and_t_input = quanti.p_b_and_u_matched\n",
    "\n",
    "class AWGN_Discrete_Density_Evolution_class_QAM(AWGN_Discrete_Density_Evolution_class):\n",
    "    \"\"\"Inherited from base class AWGN_Discrete_Density_Evolution_class.\n",
    "\n",
    "        Adapted version for an regular LDPC code, an AWGN channel and QAM modulation.\n",
    "        Thus, the quantizer is replaced.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sigma_n2_, AD_max_abs_,cardinality_Y_channel_, cardinality_T_channel_,\n",
    "                 cardinality_T_decoder_ops_,filename_H_,\n",
    "                 encoding_table,sqrt_M,i_max_, nror_,match=True):\n",
    "\n",
    "        self.match = match\n",
    "        self.filename_H = filename_H_\n",
    "        self.H_sparse = self.load_check_mat(self.filename_H)\n",
    "        self.set_code_parameters()\n",
    "        self.encoding_table = encoding_table\n",
    "        self.sqrt_M = sqrt_M\n",
    "        self.num_bits = int(np.log2(sqrt_M) * 2)\n",
    "\n",
    "        AWGN_Discrete_Density_Evolution_class.__init__(self, sigma_n2_,\n",
    "                                                       AD_max_abs_, cardinality_Y_channel_, cardinality_T_channel_,\n",
    "                                                       cardinality_T_decoder_ops_, self.d_v_max, self.d_c_max,\n",
    "                                                       i_max_, nror_)\n",
    "\n",
    "\n",
    "\n",
    "        self.EbN0 = -10 * np.log10(self.sigma_n2 * self.R_c * self.num_bits)\n",
    "        pass\n",
    "\n",
    "\n",
    "    def build_quantizer(self):\n",
    "        \"\"\"Generates a quantizer of the AWGN channel output where the used modulation scheme is QAM.\"\"\"\n",
    "\n",
    "        quanti = AWGN_Channel_Quantizer_QAM(self.sigma_n2,\n",
    "                                                 self.AD_max_abs,\n",
    "                                                 self.cardinality_T_channel,\n",
    "                                                 self.cardinality_Y_channel,\n",
    "                                                 self.encoding_table,\n",
    "                                                 sqrt_M=self.sqrt_M )\n",
    "        if self.match:\n",
    "            self.p_x_and_t_input = quanti.p_b_and_u_matched\n",
    "        else:\n",
    "            self.p_x_and_t_input = quanti.p_b_and_u_matched_no_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "55c96426c209bb0b838a038f619d6b23b91504976d406b82cd1da81686961396"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
